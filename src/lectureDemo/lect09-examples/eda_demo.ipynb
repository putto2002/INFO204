{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis (EDA) forms an important part of all data science work (indeed, some argue that exploratory data analysis ***is*** data science under an older name!). Here, we will walk through a very basic example of EDA - there's really a whole lot more that coud be covered, but ... baby steps, eh? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "data = pd.read_csv('eda-demo.csv')\r\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing anything, it's a good idea to get some basic descriptive statistics of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())\r\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a guess (but a reasonable one) that the purpose of this data is to inform the process of building a model to predict the <code>target</code> variable using the other known variables. Looks like we're dealing solely with numeric data (phew! no need to transform or dummy encode any data here) - normally, this would be the place that you'd perform any obvious transformations and data cleaning prior to using the data. For example, in Lab 4, you could have removed the Make and Model, and cleaned up the Transmission variable at this point.\r\n",
    "\r\n",
    "Seeing as all our data is numeric, let's have a quick look at the correlations between our variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\r\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a couple of interesting things there (e.g., the high correlation between y and z) - perhaps they'll be easier to see/understand when we visualise them.\r\n",
    "\r\n",
    "## Visualisation\r\n",
    "\r\n",
    "Visualisation plays an important part in EDA - some trends are easier to pick up visually rather than by analysing tables of data. Let's start by visualising our correlations from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.correlation import plot_corr\r\n",
    "\r\n",
    "cp = plot_corr(corr, xnames=corr.columns.values)\r\n",
    "cp.set_figwidth(8)\r\n",
    "cp.set_figheight(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, looks like there's some strong correlations to play with here, and a couple that we may want to look into further (e.g., the strong correlation between x and y, and the weak correlation between d and everything else). Let's examine the scatter plots to get some more ideas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\r\n",
    "\r\n",
    "pairs = sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, looks like we can definitely get rid of d - it doesn't look like it is contributing anything of use in terms of predicting the target.\r\n",
    "\r\n",
    "x, y, and z all look useful, but the interaction between y and z seems pretty strong (almost like one is a noisy copy of the other!). It doesn't look like we get much extra information by keeping both of them. Given that y is slightly stronger in terms of correlation to the target than z, it looks like we should keep y and discard z.\r\n",
    "\r\n",
    "In terms of their relationship to the target, both x and x have fairly strong non-linearities (albeit in opposite directions). We may be able to \"linearise\" them with a set of simple transformations (see the lecture for some candidates).\r\n",
    "\r\n",
    "So, our quick venture into EDA has suggested a couple of things:\r\n",
    "1. Get rid of the z and d features\r\n",
    "2. Perform a transformation on x and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping the transformations\r\n",
    "\r\n",
    "Let's apply the transformations suggested by EDA to a copy of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "trans = data.copy(deep=True)\r\n",
    "trans['x'] = np.log(trans['x'])\r\n",
    "trans['ysqr'] = trans['y']**2  ## note that, instead of replacing y with y^2, we add a new column, this is a useful thing to explore sometimes\r\n",
    "trans.drop(columns=[ 'z', 'd' ], inplace=True)\r\n",
    "\r\n",
    "sns.pairplot(trans[[ 'x', 'y', 'ysqr', 'target' ]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's certainly _some_ improvement in our features (the $y^2$ transformation in particular seems to be useful). The relationship between target and x is a little better, too (we could try a different type of transformation, but this will do for now!).\r\n",
    "\r\n",
    "We're ready for modelling. We'll use a cross validation scheme (see Lecture 10) to assess the generalisation performance of our model. First, let's see how well a linear model would have performed on our \"raw\" data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "\r\n",
    "from sklearn.model_selection import cross_val_score, KFold\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "\r\n",
    "X = data.drop(columns=['target']).to_numpy()\r\n",
    "y = data['target'].to_numpy()\r\n",
    "\r\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1234)\r\n",
    "rsqr = cross_val_score(LinearRegression(), X, y, cv=kf)\r\n",
    "print(\"Linear Regression on raw features: R^2={}, std={}\".format(np.mean(rsqr), np.std(rsqr)))\r\n",
    "\r\n",
    "_ = plt.figure()\r\n",
    "scatter = sns.scatterplot(x=y, y=LinearRegression().fit(X, y).predict(X))\r\n",
    "plt.xlabel('y (target)')\r\n",
    "plt.ylabel('$\\\\hat{y}$')\r\n",
    "plt.title('Linear Regression Model Fit (Pre EDA)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a clear non-linear relationship between the predictions and the known target values. The $R^{2}$ value of 0.87 is not bad, but it's clear that the linear model is not picking up all the nuance of the relationships in the data. Let's see what happens when we take the EDA into consideration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "\r\n",
    "from sklearn.model_selection import cross_val_score, KFold\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "\r\n",
    "X = trans.drop(columns=['target']).to_numpy()\r\n",
    "y = trans['target'].to_numpy()\r\n",
    "\r\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1234)\r\n",
    "rsqr = cross_val_score(LinearRegression(), X, y, cv=kf)\r\n",
    "print(\"Linear Regression on post-EDA transformed and removed features: R^2={}, std={}\".format(np.mean(rsqr), np.std(rsqr)))\r\n",
    "\r\n",
    "_ = plt.figure()\r\n",
    "scatter = sns.scatterplot(x=y, y=LinearRegression().fit(X, y).predict(X))\r\n",
    "plt.xlabel('y (target)')\r\n",
    "plt.ylabel('$\\\\hat{y}$')\r\n",
    "plt.title('Linear Regression Model Fit (Post EDA)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualisation and $R^{2}$ score of 0.97 clearly show that the modelling process now captures a lot more of the relationship between the target and the input features. Note that exactly the same process of fitting the model was used, so the improvement that we see is through to our analysis of the features and a hand-crafted approach to tuning the process via simple feature transformations.\r\n",
    "\r\n",
    "## The End\r\n",
    "Of course, not all EDA processes will end up as successful as this one was. There's going to be times where we need more sophisticated methods to automatically construct new feature tansformations for us (see Neural Networks!). However, the EDA process still remains an important part of data science work, and should be the FIRST thing that you conduct prior to going heads-first into the \"state-of-the-art\" modelling techniques!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62fc2651464dad1995679e4979df85253fe0ba849c20d35dee3a67868f9f30b2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
