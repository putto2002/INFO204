{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05b0366",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "As discussed in lectures, cross validation is a technique that allows us to efficiently use our available data for both training and evaluation purposes. It does this by assigning each observation in the training data to one of $k$ folds, and then one-by-one removing a fold from the data, fitting a model on the remaining data, and then evaluating the resulting model on the removed fold. This results in $k$ measures of performance, and to obtain the cross validation performance, we can (for example) simply take the mean of these values.\n",
    "\n",
    "The following examples start with a long version approach to cross validation (for reference only - DO NOT USE THIS APPROACH), and then demonstrate how to apply cross validation through the functionality provided by scikit-learn.\n",
    "\n",
    "## Our Data\n",
    "We start with the following set of data (pertaining to a set of fuel efficiency readings for some rather old cars from the 1970s - around the time of the [Oil Crisis](https://en.wikipedia.org/wiki/1970s_energy_crisis)) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da9ba71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "auto_data = pd.get_dummies(pd.read_csv('auto.csv'))\n",
    "\n",
    "X, y, = auto_data.drop(columns=['mpg']).to_numpy(), auto_data['mpg'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7298c",
   "metadata": {},
   "source": [
    "## Estimating generalisation performance through cross validation\n",
    "We can use cross validation to obtain an estimate for the generalisation performance we can expect for a given model (which we can then use to honestly compare the performance of a set of candidate models). A hand-crafted way of doing this is as follows: (note: DO NOT USE THIS APPROACH!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6eda8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation R-Squared performance of linear regression is 0.814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "## set up the fold for each training instance\n",
    "n_folds = 10\n",
    "fold = np.array([ i % n_folds for i in range(len(X)) ])\n",
    "rng.shuffle(fold)\n",
    "\n",
    "## now, iterate over each fold\n",
    "perf = []\n",
    "for i in range(n_folds):\n",
    "    ## split the data into training and testing sets according to the current fold\n",
    "    X_train, X_test, y_train, y_test = X[np.where(fold != i)], X[np.where(fold == i)], y[np.where(fold != i)], y[np.where(fold == i)]\n",
    "    ## fit a model on the current training set\n",
    "    mdl = LinearRegression().fit(X_train, y_train)\n",
    "    ## evaluate the performance of the model on the current test set, and append this to the list of performance results over all folds\n",
    "    perf.append(mdl.score(X_test, y_test))\n",
    "\n",
    "## use the perf results as an estimate of generalisation performance\n",
    "print(\"Cross validation R-Squared performance of linear regression is {}\".format(np.round(np.mean(perf), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84aae3",
   "metadata": {},
   "source": [
    "Cross validation is a ***very*** common activity. Therefore, scikit-learn provides an easy-to-use framework to perform cross validation. The above sequence can be replaced with the following equivalent code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9265d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "perf = cross_val_score(LinearRegression(), X, y, cv=kf)\n",
    "print(\"Cross validation R-Squared performance of linear regression is {}\".format(np.round(np.mean(perf), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e4b0c9",
   "metadata": {},
   "source": [
    "Note that the score returned may not be _exactly_ the same (it is an estimate, after all) as the allocation of instances to folds has a random element to it. To reduce this effect, and therefore produce more stable estimates, you may wish to use the _repeated cross validation_ approach, which simply repeats the $k$-fold cross validation process a given number of times. For example, the above code can be slightly modified to perform 3 rounds of 10-fold cross validation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711776dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=3) ## note that this is the ONLY line of code that has changed!\n",
    "perf = cross_val_score(LinearRegression(), X, y, cv=kf)\n",
    "print(\"Cross validation R-Squared performance of linear regression is {}\".format(np.round(np.mean(perf), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5778eb6d",
   "metadata": {},
   "source": [
    "Looks like $R^{2}$ values of around 0.8 are typical for linear regression on this data.\n",
    "\n",
    "Now that we have a simple method of obtaining cross validation estimates of performance for a learning algorithm, we can now use it to compare (and therfore _select_ from) a range of models. For example, we could compare linear regression to k-Nearest Neighbours (both with and without standardisation) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "## to incorporate feature standardisation into kNN, we need to create a pipeline that first performs standardisation, and then builds the model\n",
    "zknn_pipe = Pipeline([\n",
    "    ( 'scaler', StandardScaler()),\n",
    "    ( 'model', KNeighborsRegressor(n_neighbors=3))\n",
    "])\n",
    "\n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=3) ## note that this is the ONLY line of code that has changed!\n",
    "lm = cross_val_score(LinearRegression(), X, y, cv=kf)\n",
    "knn = cross_val_score(KNeighborsRegressor(n_neighbors=3), X, y, cv=kf)\n",
    "zknn = cross_val_score(zknn_pipe, X, y, cv=kf)\n",
    "\n",
    "print(\"Cross validation R-Squared performance of linear regression is {}\".format(np.round(np.mean(lm), 3)))\n",
    "print(\"Cross validation R-Squared performance of 3-neighbour kNN is {}\".format(np.round(np.mean(knn), 3)))\n",
    "print(\"Cross validation R-Squared performance of 3-neighbour standardised kNN is {}\".format(np.round(np.mean(zknn), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4859c3",
   "metadata": {},
   "source": [
    "Looks like standardised 3-neighbour kNN works well on this data (although it doesn't provide us any insights into the problem itself - but this is not what we're concerned with right now!). If desired, we can use the raw performance results rather than the aggregated values. For example, we could produce a boxplot of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dccec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plot_data = pd.DataFrame({\n",
    "    'Linear Regression' : lm,\n",
    "    '3-Neighbour kNN' : knn,\n",
    "    '3-Neighbour Standardised kNN' : zknn\n",
    "})\n",
    "\n",
    "\n",
    "ax = sns.boxplot(data=plot_data);\n",
    "ax.figure.set_size_inches(10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b8dbe4",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation via cross validation\n",
    "\n",
    "As mentioned in the lecture, different combinations of hyperparameter settings produce different models, so we can treat the search for good hyperparameter settings as a model selection problem. The general idea is as follows:\n",
    "1. Generate a list of possible hyperparameter settings\n",
    "2. For each set of hyperparameter values in the list, compute the cross validation performance of the resulting model\n",
    "3. Pick the set of hyperparameter values that produced the model with the highest cross validation performance\n",
    "4. Build a model on the entire data set using the selected hyperparameter settings.\n",
    "\n",
    "Lets look at the manual process that would be used for selecting the neighbourhood size for kNN: (again, this is for demonstration only - DO NOT USE THIS APPROACH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "## set up the hyperparameters that we'd like to explore - if we explore a lot of different \n",
    "## values for a large combination of hyperparameters, then this list could be VERY large\n",
    "candidate_neighbourhoods = [ 1, 3, 5, 7, 9, 11, 31, 51, 71, 91, 101, 201 ]\n",
    "\n",
    "## set up the fold for each training instance\n",
    "n_folds = 10\n",
    "fold = np.array([ i % n_folds for i in range(len(X)) ])\n",
    "rng.shuffle(fold)\n",
    "\n",
    "## now for each item in the hyperparameter list, compute the CV performance\n",
    "scaler = StandardScaler()\n",
    "neighbourhood_perf = []\n",
    "for i, k in enumerate(candidate_neighbourhoods):    \n",
    "    ## now, iterate over each fold\n",
    "    perf = []\n",
    "    for i in range(n_folds):\n",
    "        ## split the data into training and testing sets according to the current fold\n",
    "        X_train, X_test, y_train, y_test = X[np.where(fold != i)], X[np.where(fold == i)], y[np.where(fold != i)], y[np.where(fold == i)]\n",
    "        Z_train, Z_test = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "        \n",
    "        ## fit a model on the current training set\n",
    "        mdl = KNeighborsRegressor(n_neighbors=k).fit(Z_train, y_train)\n",
    "        ## evaluate the performance of the model on the current test set, and append this to the list of performance results over all folds\n",
    "        perf.append(mdl.score(Z_test, y_test))\n",
    "    neighbourhood_perf.append(np.mean(perf))\n",
    "\n",
    "## extract the stats of the best hyperparameters\n",
    "best_neighbourhood = np.argmax(neighbourhood_perf)\n",
    "best_k = candidate_neighbourhoods[best_neighbourhood]\n",
    "best_perf = neighbourhood_perf[best_neighbourhood]\n",
    "\n",
    "## And now report\n",
    "print(\"Cross validation suggests that a neighbourhood size of {} yields a model with performance of {}\".format(best_k, np.round(best_perf, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ec7db",
   "metadata": {},
   "source": [
    "Of course, we can plot this result to see the trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plot_data = pd.DataFrame({\n",
    "    'k' : candidate_neighbourhoods,\n",
    "    'CV R-Squared' : neighbourhood_perf\n",
    "})\n",
    "\n",
    "ax = sns.lineplot(data=plot_data, x='k', y='CV R-Squared')\n",
    "sns.scatterplot(data=plot_data.iloc[[best_neighbourhood]], x='k', y='CV R-Squared', color='#ce2227');\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('CV $R^{2}$')\n",
    "ax.set_xscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c26a1",
   "metadata": {},
   "source": [
    "From this plot, we can see that the performance of kNN is maximised at a neighbourhood size of 3, is roughly even between 3-7, and quickly degrades after a neighbourhood size $k$ greater than 7. Because their scores are so similar, it is likely than any neighbourhood size between 3 and 9 (inclusive) would be selected (due to the small fluctations we might expecte through cross validation).\n",
    "\n",
    "As with evaluating a single model performance, scikit-learn provides a convenience framework from which to evaluate potential hyperparameter settings and fit the \"optimal\" model to data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ce73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=3) ## note that this is the ONLY line of code that has changed!\n",
    "\n",
    "## to incorporate feature standardisation into kNN, we need to create a pipeline that first performs standardisation, and then builds the model\n",
    "zknn_pipe = Pipeline([\n",
    "    ( 'scaler', StandardScaler()),\n",
    "    ( 'model', KNeighborsRegressor(n_neighbors=3))\n",
    "])\n",
    "\n",
    "## set up the hyperparameters that we'd like to explore - if we explore a lot of different \n",
    "## values for a large combination of hyperparameters, then this list could be VERY large\n",
    "##\n",
    "## the framework that we'll be using needs this to be set up as a dictionary with one\n",
    "## entry for each hyperparameter - the framework will work out all the combinations\n",
    "## for you\n",
    "candidate_neighbourhoods = [ 1, 3, 5, 7, 9, 11, 31, 51, 71, 91, 101, 201 ]\n",
    "param_grid = {\n",
    "    'model__n_neighbors' : candidate_neighbourhoods\n",
    "}\n",
    "\n",
    "## now, construct the object that will search through the hyperparameters and fit the best model for you\n",
    "cv = GridSearchCV(zknn_pipe, param_grid=param_grid, cv=kf)\n",
    "cv.fit(X, y)\n",
    "\n",
    "## extract the stats of the best hyperparameters\n",
    "best_k = cv.best_params_\n",
    "best_perf = cv.best_score_\n",
    "\n",
    "## And now report\n",
    "print(\"Cross validation suggests that a neighbourhood size of {} yields a model with performance of {}\".format(best_k, np.round(best_perf, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9b326",
   "metadata": {},
   "source": [
    "The full details of the hyperparameter search are stored in the <code>cv_results_</code> property of the GridSearchCV object once the model has been fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b25c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_data = pd.DataFrame(cv.cv_results_)\n",
    "cv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29434c5c",
   "metadata": {},
   "source": [
    "And, as before, we can use this information to plot the results of our search to observe any useful trends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae32cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.lineplot(data=cv_data, x='param_model__n_neighbors', y='mean_test_score')\n",
    "sns.scatterplot(data=cv_data.iloc[[cv.best_index_]], x='param_model__n_neighbors', y='mean_test_score', color='#ce2227');\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('CV $R^{2}$')\n",
    "ax.set_xscale('log');"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "537143f7b593fd0d47db82ce2b5e43889682b93f538860d1dda0281ea3ca0611"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
