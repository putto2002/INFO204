{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad54005e-73f0-4c1a-9610-a1712fc90c01",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbour Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab9fa6-2e98-4204-a9f9-48a7d77b514b",
   "metadata": {},
   "source": [
    "As discussed in class, the k-Nearest Neighbours method works by exploiting an existing database of _labelled_ observations. To predict the (unknown) value of a new observation, we embed it in the space of the existing observations measure the distance between the new instance and the existing observations, and then use the labels of the $k$ nearest observations to determine the prediction. In the context of classification, the prediction is the majority label found within the labels of the $k$ nearest neighbours.\n",
    "\n",
    "To work with k-Nearest Neighbours in Python, we an make use of the existing [numpy](https://numpy.org/) and [scikit-learn](https://scikit-learn.org/) libraries. Let's start by importing them (and a [matplotlib](https://matplotlib.org/) for some plotting of the results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91cdcc4-8b6b-4d43-b81a-c895c4274e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d445e6-ad96-4bf7-ac43-645eb0bf94c9",
   "metadata": {},
   "source": [
    "## Our \"Training\" Data\n",
    "\n",
    "We'll also need some data to act as the historical observations from our problem. For this example, we'll just make some up (but usually, you'd be given this data). In this case, we (the people doing the work) actually know the underlying function $f(X)$, but from the modelling perspective this function is not known:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf508bc3-590f-4dca-8602-b874a1d04210",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the true underlying \"generating\" function of our problem, in this case\n",
    "## we are using it to separate our data into two classes \"a\" and \"b\" depending\n",
    "## upon where in a 2-D space an instance sits.\n",
    "##\n",
    "## AS WITH REGRESSION, LET'S PRETEND THAT WE DON'T KNOW THIS ONE :)\n",
    "def f(X):\n",
    "    t = 0.444*(X[:, 0] + 0.5)**2 + 0.5*np.sin(np.pi * X[:, 0])\n",
    "    return np.where(X[:, 1] > t, 1, 0)\n",
    "class_labels = np.array([ 'a', 'b' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc4e91-4816-499e-9f49-3edd18e9444c",
   "metadata": {},
   "source": [
    "Now, we will use this function to generate some training data (it is still called training data, even though no real training takes place in k-Nearest Neighbours):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83fbfe-8bac-4657-94fe-217e63e44241",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1234) ## notice the fixed seed for reproducability\n",
    "\n",
    "n_points = 50\n",
    "X_train = rng.uniform(-1, 1, size=(n_points, 2))\n",
    "y_train = f(X_train)\n",
    "X_train += rng.normal(0, 0.05, size=X_train.shape) ## let's just add a little noise to our data to make it interesting\n",
    "\n",
    "## we'll also generate some \"test\" data use this to test the shape of our learned function shortly\n",
    "n_test = 50\n",
    "xx1, xx2 = np.meshgrid(np.linspace(-1.1, 1.1, n_test), np.linspace(-1.1, 1.1, n_test))\n",
    "X = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "y = f(X)\n",
    "Z = y.reshape(xx1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea07dd38-39e9-4e62-90ae-be444aa56dfe",
   "metadata": {},
   "source": [
    "Let's take a look at the data (and underlying generating function) before moving on to modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1db66-0b81-4a92-bed6-0b63d3b2fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(-1, 1, 500)\n",
    "t = 0.444*(a + 0.5)**2 + 0.5*np.sin(np.pi * a)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], color=np.where(y_train==1, 'orange', 'cornflowerblue'))\n",
    "plt.plot(a, t, color='black', label='True Underlying Class Separator - f(X)')\n",
    "plt.title('Our Sampled Training Data')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e059c64-7428-4ae8-9444-74aa6c12bbe9",
   "metadata": {},
   "source": [
    "Note that the black line ($f(X)$) serves as the point of separation between two classes (although we've added a little noise to our instances, so there's a couple that manage to sneak over to opposite sides of this boundary). Remember, the function that this line represents is not known to k-Nearest Neighbours - its job is to estimate this function from available training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c70861-2519-4024-aecc-f858b7f24c99",
   "metadata": {},
   "source": [
    "## Applying k-Nearest Neighbours\n",
    "\n",
    "Now that we have a training set of data, we can move onto modelling. We do this by instantiating a KNeighboursRegressor model, calling the fit function, and then making predictions from the resulting model with the predict function. When building a k-Nearest Neighbours model, we need to specify the size of the neighbourhood of similar observations ($k$) - here we will examine this process for a range of $k$ values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f2789-a001-4ee2-88e1-458de6e3c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(2, 3, figsize=(16,10))\n",
    "for (i, k) in enumerate([ 1, 3, 5, 10, 20, n_points ]):\n",
    "    mdl = KNeighborsClassifier(n_neighbors=k)\n",
    "    mdl.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = mdl.predict(X)\n",
    "    Z = y_pred.reshape((50, 50))\n",
    "\n",
    "    loss = accuracy_score(y, y_pred)\n",
    "    r = i // 3\n",
    "    c = i % 3\n",
    "    ax[r, c].contourf(xx1, xx2, Z, cmap=ListedColormap(['cornflowerblue', 'orange']), alpha=0.2)\n",
    "    ax[r, c].scatter(X_train[:, 0], X_train[:, 1], color=np.where(y_train == 1, 'orange', 'cornflowerblue'), label='Sampled Training Data')\n",
    "    ax[r, c].plot(a, t, color='black', label='True Underlying Class Separator - f(X)')\n",
    "    ax[r, c].set_title(\"kNN Performance, k={}, Accuracy={}\".format(k, np.round(loss, 2)))\n",
    "    ax[r, c].set_xlabel('x1')\n",
    "    ax[r, c].set_ylabel('x2')\n",
    "    ax[r, c].set_xlim(-1.1, 1.1)\n",
    "    ax[r, c].set_ylim(-1.1, 1.1)\n",
    "    ax[r, c].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5427ad9-0534-456d-b498-d71888c40379",
   "metadata": {},
   "source": [
    "In each plot, the red line represents the model that was extracted from the training data by the algorithm for a given $k$ value. Notice that when $k=1$, the resulting model is quite sensitive to noise in the training data (it captures a lot of this noise in the model and so the class boundaries that it produces deviate from the true underlying function). As $k$ is increased, the resulting models become less sensitive to the noise in the training data. However, there is a balancing act here: as $k$ becomes very large, k-Nearest Neighbours starts to lose some of the detail in the underlying function. At its extreme ($k$ equals the size of the training data), the algorithm produces a model that is equivalent to the mean of the training data for all cases (hence all instances would be predicted as the same class).\n",
    "\n",
    "In this case, we used a training set of 50 observations - you may wish to modify the code above so that a larger traning set is used (this can be done by modifying the n_points variable to be larger, say 250 observations). Try this and note the impact that this has on estimating the class boundaries.\n",
    "\n",
    "## Examining the effect of $k$\n",
    "The main hyperparameter for k-Nearest Neighbours (indeed, the ONLY hyperparameter for the basic version of k-Nearest Neighbours) is the neighbourhood size $k$. In the previous step, we looked at an arbitrary set of possible values for $k$ - let's now be a little more rigorous and examine the performance of k-Nearest Neighbours over a more thorough sweep of values of $k$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda58201-31a4-4ce8-8742-fc72c103d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_k = np.arange(1, n_points+1)\n",
    "acc = []\n",
    "for k in all_k:\n",
    "    mdl = KNeighborsClassifier(n_neighbors=k)\n",
    "    mdl.fit(X_train, y_train)\n",
    "    acc.append(accuracy_score(y, mdl.predict(X)))\n",
    "best_k = np.argmax(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c487f-081d-43c3-8a38-82d8e66b4463",
   "metadata": {},
   "source": [
    "Finally, we can plot the loss against the neighbourhood size to see how $k$ influences the behaviour of the algorithm and the resulting model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f5534-1d39-4aa6-9915-401b15d91797",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_k, acc)\n",
    "plt.scatter(all_k[best_k], acc[best_k], color='#ce2227', label=\"Best Accuracy, k={}\".format(all_k[best_k]))\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('kNN Performance for Neighbourhood Size')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b6871-ff02-4135-a845-c087a0f4bf6a",
   "metadata": {},
   "source": [
    "Note here that we are measuring accuracy, so a larger score is better (unlike in regression, where we were measuring error, so a lower score was better).\n",
    "\n",
    "In this result, we can see that (for this sample of training data!) the best accuracy can be achieved with $k$ set to 1. However, we can also see that the trend for increasing $k$ is quite noisy up to around $k$ equals 20, so really any of these values would have worked well. After $k=20$, performance gets progressively worse with larger values of $k$ (due to increasing underfitting of the data). We will discuss this (and strategies for algorithmic tuning and model selection) in later lectures.\n",
    "\n",
    "As mentioned above, you should repeat this step with a larger training set to see if there is any noteworthy change in behaviour."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
