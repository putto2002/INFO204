{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad54005e-73f0-4c1a-9610-a1712fc90c01",
   "metadata": {},
   "source": [
    "# Decision Trees and CART - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab9fa6-2e98-4204-a9f9-48a7d77b514b",
   "metadata": {},
   "source": [
    "As discussed in class, Classification and Regression Trees (CART) work by partitioning space of possible solutions into simpler subsets through a hierarchy of tests on the input features. To predict the (unknown) value of a new observation, we examine the split condition at each point in the tree, test the condition against the features of the new observation and follow the \"true\" or \"false\" path accordingly. We repeat this process until we reach a leaf of the tree, as which point the prediction is made by returning the value residing at the leaf node. In the context of regression, the value of the leaf nodes is the mean of the response values of the training data that reside at the point in space represented by the node.\n",
    "\n",
    "To work with CART in Python, we an make use of the existing [numpy](https://numpy.org/) and [scikit-learn](https://scikit-learn.org/) libraries. Let's start by importing them (and a [matplotlib](https://matplotlib.org/) for some plotting of the results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91cdcc4-8b6b-4d43-b81a-c895c4274e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d445e6-ad96-4bf7-ac43-645eb0bf94c9",
   "metadata": {},
   "source": [
    "## Our \"Training\" Data (this is identical to Lecture 5)\n",
    "\n",
    "We'll also need some data to act as the historical observations from our problem. For this example, we'll just make some up (but usually, you'd be given this data). In this case, we (the people doing the work) actually know the underlying function $f(X)$, but from the modelling perspective this function is not known:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf508bc3-590f-4dca-8602-b874a1d04210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    return (X[:, 0] + 0.5)**2 + 0.25 * np.sin(4 * np.pi * X[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc4e91-4816-499e-9f49-3edd18e9444c",
   "metadata": {},
   "source": [
    "Now, we will use this function to generate some training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83fbfe-8bac-4657-94fe-217e63e44241",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1234) ## notice the fixed seed for reproducability\n",
    "\n",
    "n_points = 50\n",
    "X_train = rng.uniform(-1, 1, size=n_points).reshape((-1, 1))\n",
    "y_train = f(X_train) + rng.normal(0, 0.1, size=len(X_train))\n",
    "\n",
    "## we'll also generate some \"test\" data use this to test the shape of our learned function shortly\n",
    "X = np.linspace(-1, 1, 500).reshape((-1, 1))\n",
    "y = f(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea07dd38-39e9-4e62-90ae-be444aa56dfe",
   "metadata": {},
   "source": [
    "Let's take a look at the data (and underlying generating function) before moving on to modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1db66-0b81-4a92-bed6-0b63d3b2fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, alpha=0.2, label='Sampled Training Data')\n",
    "plt.plot(X, y, color='black', label='True Underlying Function - f(X)')\n",
    "plt.title('Our Sampled Training Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c70861-2519-4024-aecc-f858b7f24c99",
   "metadata": {},
   "source": [
    "## Applying CART\n",
    "\n",
    "Now that we have a training set of data, we can move onto modelling. We do this by instantiating a DecisionTreeRegressor model, calling the fit function, and then making predictions from the resulting model with the predict function. When building a CART model, we need to specify the minimum split size of a node (called <code>min_samples_split</code> in scikit-learn)) - here we will examine this process for a range of <code>min_samples_split</code> values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f2789-a001-4ee2-88e1-458de6e3c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(2, 3, figsize=(16,10))\n",
    "for (i, k) in enumerate([ 2, 3, 5, 10, 25, 2*n_points ]):\n",
    "    mdl = DecisionTreeRegressor(random_state=0, min_samples_split=k)\n",
    "    mdl.fit(X_train, y_train)\n",
    "    leaf_loss = mean_squared_error(f(X), mdl.predict(X))\n",
    "\n",
    "    r = i // 3\n",
    "    c = i % 3\n",
    "    ax[r, c].scatter(X_train, y_train, alpha=0.2, label='Sampled Training Data')\n",
    "    ax[r, c].plot(X, f(X), color='black', label='True Underlying Function - f(X)')\n",
    "    ax[r, c].plot(X, mdl.predict(X), color='#ce2227', label=\"Estimated Function - CART, minsplit={}\".format(k))\n",
    "    ax[r, c].set_title(\"CART Performance, MSE={}\".format(np.round(leaf_loss, 2)))\n",
    "    ax[r, c].set_xlabel('X')\n",
    "    ax[r, c].set_ylabel('y')\n",
    "    ax[r, c].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5427ad9-0534-456d-b498-d71888c40379",
   "metadata": {},
   "source": [
    "In each plot, the red line represents the model that was extracted from the training data by the algorithm for a given <code>min_samples_split</code> value. Notice that when <code>min_samples_split</code>=2, the resulting model is quite sensitive to noise in the training data (it captures a lot of this noise in the model and so it regularly deviates from the true underlying function). As <code>min_samples_split</code> is increased, the resulting models become less sensitive to the noise in the training data. However, there is a balancing act here: as <code>min_samples_split</code> becomes very large, CART starts to lose some of the detail in the underlying function. At its extreme (<code>min_samples_split</code> is largerthan size of the training data), the algorithm produces a model that is equivalent to the mean of the training data for all cases (hence the stright line).\n",
    "\n",
    "## Visualising the CART model\n",
    "In the above examples, CART was run on the same data six times with different values for <code>min_samples_split</code>, which resulted in six different trees being produced. One of the most valuable aspect of CART is that, for reasonably small trees, the model is highly interpretable (i.e., we can read the tree as a series of rules, and we can visualise the tree as a hierarchical series of splitting rules. To visualise a tree, we can use the <code>plot_tree</code> function from scikit-learn. For example, the six models created in the previous cell can be visualised as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511a518-943d-4fd8-848b-5f0f616bf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(2, 3, figsize=(16, 10))\n",
    "for (i, k) in enumerate([ 2, 3, 5, 10, 25, 2*n_points ]):\n",
    "    mdl = DecisionTreeRegressor(random_state=0, min_samples_split=k)\n",
    "    mdl.fit(X_train, y_train)\n",
    "    leaf_loss = mean_squared_error(f(X), mdl.predict(X))\n",
    "\n",
    "    r = i // 3\n",
    "    c = i % 3\n",
    "    plot_tree(mdl, ax=ax[r, c], feature_names=[ 'X' ], rounded=True, label='none', proportion=False, impurity=False, filled=True)\n",
    "    ax[r, c].set_title(\"CART Performance, minsplit={}, MSE={}\".format(k, np.round(leaf_loss, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9e7fe-d2ba-436d-9b45-21950a242e28",
   "metadata": {},
   "source": [
    "We interpret the trees as follows: the leaf nodes show the number of training instances that matched the splitting criteria up to this point (top number), along with the mean of the response of these training instances (the bottom number). The interior nodes show three things: the splitting rule at this point (top row), the number of matching training instances at this point in the tree (second row), and the mean of the response of these training instances (bottom row). We read the tree as a series of if-then-else rules. For example, the CART tree resulting from <code>min_samples_split</code>=25 can be read as follows:\n",
    "<pre>\n",
    "if X <= 0.565 then\n",
    "    if X <= 0.015 then\n",
    "        if X <= -0.79 then\n",
    "            prediction = 0.417\n",
    "        else\n",
    "            prediction = 0.028\n",
    "    else\n",
    "        prediction = 0.654\n",
    "else\n",
    "    prediction = 1.745\n",
    "</pre>\n",
    "\n",
    "Note that, as <code>min_samples_split</code> _increases_, the tree complexity _decreases_, right up to the point where the tree collapses into a single node.\n",
    "\n",
    "## Examining the effect of <code>min_samples_split</code>\n",
    "The main hyperparameter for CART is the minimum node split size <code>min_samples_split</code>. In the previous step, we looked at an arbitrary set of possible values for <code>min_samples_split</code> - let's now be a little more rigorous and examine the performance of CART over a more thorough sweep of values of <code>min_samples_split</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda58201-31a4-4ce8-8742-fc72c103d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_split = np.arange(2, n_points + 1)\n",
    "split_loss = []\n",
    "for k in all_split:\n",
    "    mdl = DecisionTreeRegressor(random_state=0, min_samples_split=k)\n",
    "    mdl.fit(X_train, y_train)\n",
    "    split_loss.append(mean_squared_error(f(X), mdl.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c487f-081d-43c3-8a38-82d8e66b4463",
   "metadata": {},
   "source": [
    "Finally, we can plot the loss against the neighbourhood size to see how $k$ influences the behaviour of the algorithm and the resulting model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550f749-209f-4a77-aa4c-5d78b5507968",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_split = np.argmin(split_loss)\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "plt.plot(all_split, split_loss)\n",
    "plt.scatter(all_split[best_split], split_loss[best_split], color='#ce2227', label=\"Lowest MSE, minsplit={}\".format(all_split[best_split]))\n",
    "plt.xlabel('minsplit')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('CART Performance for minsplit')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b6871-ff02-4135-a845-c087a0f4bf6a",
   "metadata": {},
   "source": [
    "In this result, we can see that (for this sample of training data!) the lowest error can be achieved with <code>min_samples_split</code> set to 6. We can also see that performance degrades slightly when <code>min_samples_split</code> is smaller than 6 (due to overfitting the data), and error gets progressively worse with larger values of <code>min_samples_split</code> (due to increasing underfitting of the data). We will discuss this (and strategies for algorithmic tuning and model selection) in later lectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
